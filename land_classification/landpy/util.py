import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data import DataLoader
import torch
from .my_data_loader import MyDataLoader
from sklearn.metrics import jaccard_similarity_score as jsc
from sklearn.metrics import confusion_matrix  
import json
import os
from PIL import Image, ImageOps


def create_data_loaders(data_set, training_split, batch_size):
    '''
    Creates the train and validation loader to run the model

    :param data_set: Data set generated by the custom Data Loader Function
    :paramtype data_set: PyTorch DataLoader?

    :param training_split: Percentage of data that is used for training (remainder used for validation)
    :paramtype training_split: float

    :param batch_size: Batch size for the model
    :paramtype batch_size: int
    '''

    dataset_size = len(data_set)
    indices = list(range(dataset_size))
    split_1 = int(training_split * dataset_size)
    
    training_indices = indices[:split_1]
    validation_indices = indices[split_1:]
    
    train_sampler = SubsetRandomSampler(training_indices)
    validation_sampler = SubsetRandomSampler(validation_indices)
    
    train_loader = DataLoader(data_set, batch_size=batch_size, sampler=train_sampler,
        shuffle=False, pin_memory=True, drop_last=True)
    validation_loader = DataLoader(data_set, batch_size=batch_size, sampler=validation_sampler,
        shuffle=False, pin_memory=True, drop_last=True)

    return train_loader, validation_loader



def train_step(inputs, class_labels, optimizer, loss, unet):
    '''
    Completes the training step for a single batch

    ..param inputs: Training batch of satellite images
    ..paramtype: Torch Tensor

    ..param class_labels: Generated 1D image mask for coresponding satellite image
    ..paramtype: Torch Tensor

    ..param optimizer: Optimizer in use
    ..paramtype optimizer: Torch Optimizer

    ..param loss: Loss function used
    ..paramtype loss: Torch Loss

    ..param unet: The Model we are training
    ..paramtype unet: UNet custom class
    '''

    #zero out the gradients because we do not want them to accumulate on each step
    optimizer.zero_grad()
    outputs = unet(inputs)
    soft_max_output = torch.nn.LogSoftmax(dim=1)(outputs)
    loss_output = loss(soft_max_output, class_labels.long())
    pre_parameters = list(unet.parameters())[0].clone()
    loss_output.backward()
    optimizer.step()
    post_parameters = list(unet.parameters())[0].clone()

    if torch.equal(pre_parameters.data, post_parameters.data):
        print("No Update Occured")

    return loss_output


def mean_IOU(softmax_prediction_batch, actual_batch):
    '''
    Calculates the Mean Intersection over Union for a Batch

    ..param softmax_predicition_batch: The softmax output prediction from UNet Model
    ..paramtype softmax_prediction_batch: Torch Tensor

    ..param actual_batch: Actual hand labeled mask for evaluation
    ..paramtype actual_batch: Torch Tensor
    '''

    softmax_prediction = softmax_prediction_batch.cpu().numpy()
    prediction = np.argmax(softmax_prediction, axis=1)
    y_pred = prediction.flatten()

    y_true = actual_batch.cpu().numpy()
    y_true = y_true.flatten()

    current = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4,5])
    intersection = np.diag(current)
    ground_truth_set = current.sum(axis=1)
    predicted_set = current.sum(axis=0)
    union = ground_truth_set + predicted_set - intersection + 1e-8
    IoU = intersection / union.astype(np.float32)

    return np.mean(IoU)

def construct_image(prediction_label, label_mask_size):
    '''
    Takes in a prediction label and constructs a 3D RGB Image

    ..param prediction_label: The 2D prediction mask
    ..paramtype prediction_label: Numpy array

    ..param label_mask_size: The size of the mask label
    ..paramtype label_mask_size: int
    '''

    new_image = np.zeros((3,label_mask_size,label_mask_size))
    d = {
        0: (0,1,1),
        1: (1,1,0),
        2: (1,0,1),
        3: (0,1,0),
        4: (0,0,1),
        5: (1,1,1),
        6: (0,0,0)
    }
    for i in range(len(new_image[0])):
        for j in range(len(new_image[0])):
            class_ = prediction_label[i][j]
            scheme = d[class_]
            new_image[0][i][j] = scheme[0]
            new_image[1][i][j] = scheme[1]
            new_image[2][i][j] = scheme[2]
    return new_image


def calculate_output_size(input_size, first_kernel_size):
    '''
    Calculates the size of the label output due to model

    ..Future Work: Take in model as input to function and calculate using
        parameters taken from there

    ..Assumptions: 4 contracting blocks - bottleneck - 3 expansion
        ..Each contracting and expansion uses size 3 kernels except first
            kernel

    ..param input_size: Size of input image (assume square)
    ..paramtype input_size: int

    ..param first_kernel_size: Size of first convolutional kernel
    ..paramtype first_kernel_size: int

    ..return label_size: Label size output
    '''
    c_1 = input_size - ((first_kernel_size - 1)*2)
    mp_1 = c_1/2

    c_2 = mp_1 - 4
    mp_2 = c_2/2

    c_3 = mp_2 - 4
    mp_3 = c_3/2

    c_4 = mp_3 - 4
    mp_4 = c_4/2

    bottleneck = (mp_4 - 4)*2

    cat_1 = bottleneck
    e_1 = (cat_1 - 4)*2
    e_2 = (e_1 - 4)*2
    e_3 = (e_2 - 4)*2

    label_size = e_3 - 4

    return label_size

def calculate_percentages(prediction_image, output_path):
    '''
    Determines percent of pixels of specific land use

    ..param prediction_image: Numpy 2D array of prediction
    ..paramtype prediction_image: numpy array
    '''

    land_use_d = {0:"Urban", 1: "Agriculture",
        2: "Rangeland", 3: "Forest", 4: "Water",
        5: "Barren", 6: "Unknown"
    }
    flattened_list = list(prediction_image.flatten())

    count_dict = {}
    total = len(flattened_list)
    for key in land_use_d:
        num_land_use = flattened_list.count(key)
        count_dict[land_use_d[key]] = round((num_land_use/total)*100, 2)
    
    json_path = os.path.join(output_path, "output.json")
    with open(json_path, 'w') as f:
        json.dump(count_dict, f)

    return None

def crop_image(raw_image):
    '''
    Crops the image so it is square

    ..param raw_image: The image needed to be predicted
    ..paramtype raw_image: PIL Image

    ..return raw_image: Resized to form
    ..rtype: PIL Image
    '''
    width, height = raw_image.size
    limiting_size = min(width, height)
    size = limiting_size, limiting_size
    # raw_image.thumbnail(size,Image.ANTIALIAS)
    crop_image = ImageOps.fit(raw_image, size, Image.ANTIALIAS)

    return crop_image

def get_image_for_prediction(image_path, transformation):
    '''
    Creates image in proper form for predicition

    ..param image_path: File path that points to Image
    ..paramtype image_path: str

    ..param transformation: PyTorch Image Transformations
    ..paramtype transformation: torchvision.transforms

    ..return image: Proper representation of image for prediction
    ..rtype: torch tensor
    '''

    raw_image = Image.open(image_path)
    print(f"Raw Image Dimensions (Width x Height): {raw_image.size}")
    resized_image = crop_image(raw_image)
    print(f"Resized Image Dimensions (Width x Height): {resized_image.size}")
    image = transformation(resized_image)
    
    return image.unsqueeze(0)



def validation_IOU(prediction_batch, actual_batch):
    '''
    NOT IN USE - mean_IOU is used
    '''
    numpy_output = prediction_batch.cpu().numpy()
    prediction = np.argmax(numpy_output, axis=1)
    labels = actual_batch.cpu().numpy()
    jsc_labels = labels.reshape(-1)
    jsc_outputs = prediction.reshape(-1)
    
    return jsc(jsc_outputs, jsc_labels)


