# Model Architecture:
    This Model was built based on the UNet model. See references below for more information
    Paper: https://arxiv.org/abs/1505.04597
    Article: https://towardsdatascience.com/u-net-b229b32b4a71
    Source Code: https://github.com/Hsankesara/DeepResearch/blob/master/UNet/Unet.py
  
# Data:
## DataSet (request access to obtain): https://competitions.codalab.org/competitions/18468#learn_the_details 

    This model was trained use the DeepGlobe Land Use Classification Dataset. When you download the data, it gives you all of the
    images in a single folder - thus it is necessary to create two folders (Python file to do this coming - currently completed in
    Jupyter Notebook). These folders must be named training and masks in order to execute the code. It does not matter where you put the data since
    this path is an argument entered by the user, but within that path, there must be the training and masks folder. 

## Data Folders:
    trainging data: Training images and masks
    testing data: Satellite images with no corresponding masks
        (A genuine test set - good for visual evaluation)
  
# Recommended File Structure
    .
    ├── Data                  # Data Folders (Does not need to be at same level as land_classification)
    │   ├──satellite_images
    │   ├──masks
    .
    .
    ├── land_classification   # This Repository
    │   ├── bin               # Directory with Python files to execute training & evaluate once training is complete
    │       ├──train.py
    │       ├──evaluation.py
    │   ├── landpy            # Directory with Python files that contain all backend utilities, etc. 
    │       ├──__init__.py
    │       ├──unet.py
    │       ├──util.py
    |   ├── weights           # Contains pretrained weights
    │       ├──weights.pt
    │   ├── setup.py          # Prepares your system to run all source code - installs any necessary dependencies and connects all modules 
    │   ├── app               # Contains scripts to run a visual dashboard for analysis
    │       ├──land_use_dashboard.py
    │       ├──simple_land_use_dashboard.py
    |   ├── README.me 
    │   └── ...                
    └── ...

# Training Arguments:
    --data-dir: Defines the file path to the Data Directory above
    --start-new-model: If 1, begin training new model, if 0, start training from a previous model
    --model-to-load: Only called if start_new_model == 0; defines the path to the .pt file from a previous model
    --final-model-name: Defines the file name for the final .pt file
    --model-path: Defines the file path to save all .pt models (recommend to save under Data)
    --epoch-loss-dir: Defines the file path to the directory to save down training, validation, and execution time csv file
    --input-image-size: Defines the desired size of the input satellite image (to be resized too)
    --label-size: Defines the desired size of the label masks (to be resized too)
    --batch-size: Batch size to be used
    --epochs: Number of epochs trained on
    --learning-rate: Learning rate used for the optimizer (standard is SGD)
    --momentum: Momentum rate used for the optimizer (standard is SGD)
    --training-split: % of data used for training (remainder used for validation)
    --checkpoint: Number of epochs to execute before saving an intermediate .pt model file

# 1. Setup All Dependencies:
    pip install --user -e .
  
# 2. Example Training Command
    python bin/train.py --data-dir ../Data/training_data \
        --start-new-model 1 \
        --final-model-name land_classification_model --model-paths ../Data/models \
        --epoch-loss-dir ../Data/ --input-image-size 612  \
        --label-size 420 --batch-size 8 --epochs 300 \
        --learning-rate 0.01 --checkpoint 100 \
        --training-split 0.95 --momentum 0.9
        

# Evaluation:
    Using the pretrained weights, users can evaluate the performance of the model in a visual sense using the
    evaluation.py script located in the bin directory
    
# Evaluation Arguments:
    --data-dir: Defines the file path to the Data Directory above
    --model-path: Path to model weights
    --figure-path: Where to save the generated figure
    --input-size: Size of scaled down satellite image
    --mask-size: Size of mask that will be generated by the model
    
# Example Evaluation Command
    python bin/evaluate.py --data-dir ../Data/ --model-path weights/weights.pt --figure-path ~/models/evaluation/ --input-size          612 --mask-size 420
    
# Visual Dashboard
    Using the pretrained weights adn the land_use_dashboard script, a user can run a local instance of a web dashboard that
    shows an example of the satellite image, mask, and predicted mask
    
# Simple Dashboard Arguments
    --data-dir: Defines the file path to the Data Directory above
    --model-path: Model weights file path
    
# Dashboard Execution Command
    python app/simple_land_use_dashboard.py --data-dir ../Data/ --model-path weights/weights.pt

    
